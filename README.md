# Smart Product Pricing Challenge - ML Challenge 2025 ğŸ†

[![Python](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![License](https://img.shields.io/badge/license-MIT-green.svg)](LICENSE)
[![Status](https://img.shields.io/badge/status-active-success.svg)]()
[![Stars](https://img.shields.io/github/stars/YOUR_USERNAME/smart-pricing-ml-challenge?style=social)](https://github.com/YOUR_USERNAME/smart-pricing-ml-challenge)

> An end-to-end machine learning solution for predicting optimal e-commerce product prices using ensemble methods and advanced feature engineering.

## ğŸ“‹ Problem Statement

In e-commerce, determining the optimal price point for products is crucial for both marketplace success and customer satisfaction.

**Challenge**: Develop an ML solution that analyzes product details and predicts the price of a product. The relationship between product attributes and pricing is complex â€” factors like brand, specifications, and quantity directly influence pricing.

**Task**: Build a model that can holistically analyze product details and suggest an optimal price.

## ğŸ—‚ï¸ Data Description

The dataset consists of the following columns:

| Column | Description |
|--------|-------------|
| `sample_id` | A unique identifier for each product sample |
| `catalog_content` | Text field containing product title, description, and Item Pack Quantity (IPQ) concatenated together |
| `image_link` | Public URL of the product image. Example: https://m.media-amazon.com/images/I/71XfHPR36-L.jpg |
| `price` | Target variable â€” the product price (available only in training data) |

### Dataset Details
- **Training Dataset**: 75,000 products with complete details and prices
- **Test Dataset**: 75,000 products (without prices, for evaluation)

## ğŸ¯ Evaluation Criteria

Submissions are evaluated using **Symmetric Mean Absolute Percentage Error (SMAPE)**:

```
SMAPE = (1/n) Ã— Î£ |P_pred - P_actual| / ((|P_pred| + |P_actual|) / 2) Ã— 100
```

**Example**: If actual price = $100 and predicted price = $120
```
SMAPE = |100 - 120| / ((100 + 120) / 2) Ã— 100 = 18.18%
```

- SMAPE is bounded between 0% and 200%
- **Lower values indicate better performance**

### ğŸ† Leaderboard Details
- **Public Leaderboard**: Based on 25K samples from the test set for real-time feedback
- **Final Rankings**: Based on the full 75K test set and documentation quality

## ğŸ› ï¸ Tech Stack

- **Python 3.8+**
- **Data Processing**: Pandas, NumPy
- **Visualization**: Matplotlib, Seaborn
- **Machine Learning**: Scikit-learn
- **Gradient Boosting**: LightGBM, XGBoost
- **Development**: Jupyter Notebook

## ğŸ“ Project Structure

```
smart_pricing/
â”œâ”€â”€ dataset/
â”‚   â”œâ”€â”€ train.csv                 # Training data (75K products)
â”‚   â”œâ”€â”€ test.csv                  # Test data (75K products)
â”‚   â”œâ”€â”€ sample_test.csv           # Sample input file
â”‚   â””â”€â”€ sample_test_out.csv       # Example output format
â”œâ”€â”€ notebook/
â”‚   â””â”€â”€ price_prediction.ipynb    # Main analysis notebook
â”œâ”€â”€ output/
â”‚   â””â”€â”€ test_out.csv              # Final predictions
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ utils.py                  # Helper functions (image download)
â”‚   â””â”€â”€ sample_code.py            # Sample code reference
â”œâ”€â”€ images/                       # Downloaded product images
â”œâ”€â”€ models/                       # Saved model files
â”œâ”€â”€ README.md                     # Project documentation
â”œâ”€â”€ requirements.txt              # Python dependencies
â”œâ”€â”€ .gitignore                    # Git ignore rules
â””â”€â”€ Documentation_Report.md       # 1-page methodology report
```

## ğŸš€ Getting Started

### 1. Clone the repository
```bash
git clone https://github.com/YOUR_USERNAME/smart-pricing-ml-challenge.git
cd smart-pricing-ml-challenge
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```

### 3. Run the Jupyter notebook
```bash
jupyter notebook
```
Navigate to `notebook/price_prediction.ipynb` and run all cells.

## ğŸ§  Methodology

### Feature Engineering

#### Text Features Extracted:
- **Basic Statistics**: text length, word count, average word length
- **Item Pack Quantity (IPQ)**: Extracted using regex patterns
- **Numerical Features**: Count, average, max, min of numbers in text
- **Keyword Detection**: 
  - Premium indicators (premium, deluxe, professional, organic)
  - Size indicators (large, small, medium, XL)
  - Material keywords (cotton, plastic, metal, wood)
- **Special Characters**: Count and distribution

#### Advanced Features (Optional):
- TF-IDF vectorization of product descriptions
- Word embeddings using pre-trained models
- Brand name extraction and encoding
- Category classification

### Models Implemented

| Model | Description | Validation SMAPE |
|-------|-------------|------------------|
| **Random Forest** | Baseline ensemble model | ~XX.XX% |
| **LightGBM** | Gradient boosting, optimized for speed | ~XX.XX% |
| **XGBoost** | Extreme gradient boosting | ~XX.XX% |
| **Ensemble** | Weighted average (0.4 LGB + 0.3 XGB + 0.3 RF) | ~**XX.XX%** â­ |

### Model Architecture

```python
# LightGBM Configuration
lgb.LGBMRegressor(
    n_estimators=1000,
    learning_rate=0.05,
    max_depth=8,
    num_leaves=31,
    min_child_samples=20,
    subsample=0.8,
    colsample_bytree=0.8,
    random_state=42
)
```

### Training Pipeline

1. **Data Preprocessing**: Handle missing values, text cleaning
2. **Feature Engineering**: Extract features from catalog content
3. **Feature Scaling**: StandardScaler normalization
4. **Model Training**: Train multiple models with cross-validation
5. **Ensemble**: Combine predictions using weighted averaging
6. **Validation**: Calculate SMAPE on validation set
7. **Prediction**: Generate prices for test set

## ğŸ“Š Results

### Model Performance

| Metric | Value |
|--------|-------|
| Best Single Model | LightGBM |
| Validation SMAPE | XX.XX% |
| Public Leaderboard SMAPE | XX.XX% |
| Final Test SMAPE | XX.XX% |
| Training Time | ~XX minutes |

### Feature Importance

Top 5 most important features:
1. Pack Quantity (IPQ)
2. Maximum Number in Text
3. Text Length
4. Word Count
5. Premium Keywords

## ğŸ§¾ Output Format

The output file `test_out.csv` contains exactly two columns:

```csv
sample_id,price
12345,249.99
67890,109.00
...
```

**Requirements**:
- âœ… Exactly matches `sample_id` from test set
- âœ… Same number of rows as test data (75,000)
- âœ… All prices are positive float values
- âœ… No missing values

## âš™ï¸ Constraints & Rules

### Model Constraints
- âœ… Model must be under **8 billion parameters**
- âœ… Must use **MIT or Apache 2.0 licensed** libraries
- âœ… Predictions must be **positive floats**

### Academic Integrity - STRICTLY PROHIBITED âš ï¸
- âŒ Web scraping product prices
- âŒ Using APIs to fetch market prices
- âŒ Manual lookup from websites
- âŒ Using external pricing datasets

**This challenge tests ML problem-solving skills using ONLY the provided data.**

## ğŸ’¡ Key Features & Innovations

- âœ¨ Comprehensive text feature extraction with regex patterns
- ğŸ¤– Multi-model ensemble for robust predictions
- ğŸ“ˆ Advanced validation with cross-validation
- ğŸ¯ Optimized hyperparameters through experimentation
- ğŸ” Outlier handling and data preprocessing
- ğŸ“Š Detailed EDA and visualization

## ğŸ”® Future Improvements

- [ ] **Image Features**: Extract visual features using ResNet/EfficientNet
- [ ] **Advanced NLP**: Use BERT/RoBERTa embeddings for text
- [ ] **Hyperparameter Tuning**: Implement Optuna/GridSearchCV
- [ ] **Deep Learning**: Neural network models for multi-modal fusion
- [ ] **Brand Extraction**: Advanced NER for brand identification
- [ ] **Category Prediction**: Multi-task learning for category + price
- [ ] **Data Augmentation**: Synthetic data generation techniques

## ğŸ“ Deliverables

### 1. Output File (`test_out.csv`)
- Contains predicted prices for all 75K test samples
- Formatted according to competition requirements

### 2. Documentation Report
- **1-page report** describing:
  - Methodology used
  - Model architecture/algorithms
  - Feature engineering techniques
  - Implementation details
- Template: `Documentation_template.md`

## ğŸ“š Dependencies

```txt
pandas==2.1.0
numpy==1.24.3
matplotlib==3.7.2
seaborn==0.12.2
scikit-learn==1.3.0
lightgbm==4.0.0
xgboost==2.0.0
Pillow==10.0.0
requests==2.31.0
jupyter==1.0.0
```

Install all at once:
```bash
pip install -r requirements.txt
```

## ğŸ¤ Contributing

Contributions, issues, and feature requests are welcome! Feel free to check the [issues page](https://github.com/YOUR_USERNAME/smart-pricing-ml-challenge/issues).

### How to Contribute:
1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

## ğŸ“„ License

This project is licensed under the **MIT License** - see the [LICENSE](LICENSE) file for details.

## ğŸ‘¥ Team

**Project by**: [Your Name]

- ğŸŒ GitHub: [@your_username](https://github.com/AdityaC-07)
- ğŸ’¼ LinkedIn: [Your Profile](https://linkedin.com/in/your_profile/aditya-choudhuri-87a2a034a)
- ğŸ“§ Email: adityatarit@gmail.com

## ğŸ™ Acknowledgments

- **ML Challenge 2025** organizers for this interesting problem
- **LightGBM** and **XGBoost** communities for excellent libraries
- **Scikit-learn** for comprehensive ML tools
- All contributors and supporters of this project

## ğŸ“ Support

If you found this project helpful, please consider:
- â­ Starring the repository
- ğŸ› Reporting issues
- ğŸ’¡ Suggesting new features
- ğŸ“¢ Sharing with others

---

<div align="center">

**Made with â¤ï¸ for ML Challenge 2025**

[â¬† Back to Top](#smart-product-pricing-challenge---ml-challenge-2025-)

</div>
